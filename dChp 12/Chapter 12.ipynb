{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31899b8b",
   "metadata": {},
   "source": [
    "# Chapter 12: Custom Models and Training with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f9111d",
   "metadata": {},
   "source": [
    "### Ensure GPU Env is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60b1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc8fdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ # recently updated tf version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5fc992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__ #recently updated keras version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd37681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0368d340",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94347b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74128bac",
   "metadata": {},
   "source": [
    "## Tensors and Operations in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb36e3",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da335aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f7242f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0778a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b67d426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70c502ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49230d7",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8addf355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0a3129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[6.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1273ca21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474547aa",
   "metadata": {},
   "source": [
    "### Operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f730624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1afeb457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "670b9ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t) # @ symbol is for multiply like tf.matmul() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6170f9",
   "metadata": {},
   "source": [
    "### Keras backend in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "351fbba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77f6e7",
   "metadata": {},
   "source": [
    "## Using NumPy with TensorFlow for datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb1de241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd514ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71f88758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fcf2d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c52e95ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d63cd",
   "metadata": {},
   "source": [
    "## Issues that can occur with different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58b9d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bde4a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a91839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fee294",
   "metadata": {},
   "source": [
    "## Strings in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92bf7e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da0c4d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbe41d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Python ord() function returns the Unicode code from a given character.\n",
    "u = tf.constant([ord(c) for c in \"café\"]) \n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0edd276b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c761897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e940e",
   "metadata": {},
   "source": [
    "### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6169ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f815314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5602c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c931dc37",
   "metadata": {},
   "source": [
    "### Ragged Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b1baa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67  97 102 233], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f344e15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n"
     ]
    }
   ],
   "source": [
    "print(r[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1479d318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0fde308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e521d309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c18f07ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbdf6fb",
   "metadata": {},
   "source": [
    "### Sparse Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c5f9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99f4e83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da994275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0494afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([2. 4. 6.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s2 = s * 2.0\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c5422aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "944d2dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52e48c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fffed8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] is out of order. Many sparse ops require sorted indices.\n",
      "  Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5724caf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c23d9",
   "metadata": {},
   "source": [
    "### Sets in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1596e001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8442a25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "badf0060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbe7cf",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0799e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48247203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcfa743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f401144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36d714d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb7afbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a25816d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f1e20",
   "metadata": {},
   "source": [
    "### Tensor Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d380102",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a519c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4684075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec299f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79925ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aece24d",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b432257",
   "metadata": {},
   "source": [
    "We will build a custom loss function with the california housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce7f5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249a5124",
   "metadata": {},
   "source": [
    "Now let us build a huber loss function to use as our custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "198680b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huberloss_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abc285e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAD8CAYAAACiqQeGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABE30lEQVR4nO3deZxV8//A8de7mvYNlRYRUr5RU0pJ0UKkIlu+oeyyfhWyxFfE15afrcWSkESKRBJC0yIqIq1UlrRR2qealpn374/3LdM0zdxp7p1z75338/G4j+5y5pz36dx73/dzzufz/oiq4pxzzrnYUCToAJxzzjn3D0/MzjnnXAzxxOycc87FEE/MzjnnXAzxxOycc87FEE/MzjnnXAzxxOxcHBGR1iKiIlKpgLZ3lYikFsS2nHPGE7NzUSYiw0RkfDbPNwkl2VoBhOWci1GemJ1ziEjxoGNwzhlPzM7FiOxOU4tIrdBzTbIsfoqIzBGRNBGZLSKNs6zrVBGZIiLbRGSliLwoIuUzvT459Nz/ichaYHoe4rxBRJaKyM7Qv9dn8/riUGx/i8hnIlIs9Fp9EflSRDaLSKqI/CgibfLy/+RcovPE7Fx8+j/gHqAJ8CswXkRKgyU/YCIwDkgGLgQaAq9lWUc3QIDTgCvC2aiIXAAMAp4DTgSeB14QkXNDrzcBBgP9gLrAGcCnmVbxNrAaaBqK6SEgLbxddq5wKBZ0AM4VEu2z6USVnx/Gj6jqZwAicjWwArgMGArcBYxS1af3LCwiNwE/iEgVVV0Tevo3Vb0zj9vtDbypqoNCjxeHWuv3AB8BRwJbgXGqugVYBvyY6e+PAv5PVX8KPV6ax+07l/C8xexcwZiKtRAz3y7Lx/q+2XNHVVOBeUC90FONgW6hU8WpoR8Ee05VH5tpHbMPYrv/Yv/T3l9l2vbnWDL+TUTeEpErRaRcpmWfAYaKyCQRuV9Ejj+IGJxLaJ6YnSsY21R1aeYb1srNLCP0r2R6LukgtlUEazk3zHRLBo4D5mRabutBrPtAFCDUSj4JuAT4A+gD/CQi1UOvP4Ql8Q+AU4G5InJNBONwLu55YnYudqwN/Vst03MND7DsKXvuiEgZ7HrvotBT3wMnZP0hELptz2eMi4AWWZ5rCSzc80BVd6vqJFXtAzQAygCdMr2+RFUHqGpH4FXgunzG5FxC8WvMzsWOpcBy4CERuReoBfz3AMv+N9SbehXQF9iJdawCeBKYISIvAS8DW4DjgXNV9YZ8xvgU8K6IzMY6mLUHLsc6mCEinbDT5VOB9UAboBywSERKYZ3W3gV+Bw7HkvrMfMbkXELxxOxcjFDVXSLSFXgB6zA1B7gP2K84CXAv8DTW83kB0ElVt4bWM1dETgf+B0wBimI9t8dGIMYPROQ/WCew57DryTer6kehRTYC52M/FkoDvwDXqeq00FjpQ4Bh2FmBdaF9653fuJxLJKKqQcfgnHPOuRC/xuycc87FkLATs4gUFZEfDlDzt4SIjApVAZrptX+dc865g5OXFnNP/un1mdW1wAZVrQ08i3U+cc4551wehZWYReQIoCM2NjI7nYE3QvffA84QETnAss4555w7gHBbzM8Bd/NPAYSsamDDPFDV3cAm4LD8Buecc84VNrkOlwqNS1yjqrNFpHV+NiYiPYAeACVLlmx85JFH5md1MS0jI4MiRXL+3bNpUxIlS6ZTosSBfu/ErnD2L54l6v4tX74cVaWwf/biWTzuX3q6sHu3hPVdF4/7lxeLFy/+W1Ur57RMOOOYWwDniUgHoCRQXkRGqGq3TMusBGoCK0LTu1XAxijuQ1WHAEMA6tatqz///HN4exKHJk+eTOvWrXNdbudOEIGkgym8GKBw9y9eJer+tW7dmo0bNzJnzpygQ4maRD12e8Tb/q1YAampcHyYVdHjbf/ySkSW5bZMrj9LVLWPqh6hqrWArsCkLEkZbHq5K0P3Lw4t4wOkw3DllfDll0FH4Zxz0TF3Lnz8cdBRxJeDrvwlIg8D36nqOKze7ZsishQrw9c1QvElvNdfh5Ilg47COeeio0MHu7nw5Skxq+pkYHLoft9Mz6cBXSIZWGFRsiS88go0bQrJyUFH45xzkfP667BqFdx/f9CRxBevlR0DqleH0qWDjsI55yLr3/+G9euDjiL+eGKOAR07wsaNsHkzlC8fdDTOOZd/P/4IO3bY2UCXN4nbJz3OPPCAdwJzziWO1athWa79j112vMUcIwYMsGFTzjkX73btgvbtg44ifnmLOUaIwEsvwYcfBh2Jc87lz5NPwtNPBx1F/PIWcww59VQ45JCgo3DOufzp0we2bw86ivjlLeYY0qABqPp1Gedc/Bo/Hr7+GsqWDTqS+OUt5hgzbhxUqgRHHRV0JM45l3clS3rRpPzyxBxjbr016Aicc+7g/P03tGkDRYsGHUl881PZMeiVV+Cpp4KOwjnn8qZ/fxg+POgo4p+3mGPQuedCqVJBR+Gcc3nTvz9kxN8stjHHW8wxqGpVWLkSZswIOhLnnAvPs8/CV19BAk+lXGD8vzBGLV8Ov/0WdBTOOReeU06BWrWCjiIx+KnsGHX22fbvrl2QlBRsLM45l5NFi2y4Z5kyQUeSGLzFHMPefhvuuCPoKJxzLmdDh8KsWUFHkThybTGLSElgKlAitPx7qvpglmWuAp4CVoaeGqSqQyMbauFz/vlw8cVBR+Gccznz8puRFU6LeQfQVlWTgYZAexE5JZvlRqlqw9DNk3IElC4NixfDG28EHYlzzmWvWzeYMyfoKOJDuD3Wc03MalJDD5NCNz3oyEJWrCjFpk35XUviK13ah04552LXAw9AvXpBRxH7li6FRo3CW1ZUc8+xIlIUmA3UBgar6j1ZXr8KeBxYCywGblfV5dmspwfQwx41blyr1hQef3weVaumhRdtHElNTaVshIrFqsLffxencuWdEVlfJERy/2JRou5fr169SE9PZ+DAgUGHEjWJeuz2iKX9++qrSjRsuIGyZdMjts5Y2r9ImTevAv/974ls3pwEyGxVbZLjH6hq2DegIpACnJjl+cOAEqH7NwCTcltX8eKNFFSrVFGdMUMTTkpKSsTWNWuW6rnnRmx1ERHJ/YtFibp/rVq10uTk5KDDiKpEPXZ7xMr+ZWSo9uqlum5dZNcbK/sXKSNGqBYvrgqq55yjCnynueTHPPXKVtWNocTcPsvz61R1R+jhUKBxbus68shttGsHa9ZA69bw7rt5iaRwadLE52l2zsWWXbusqMihhwYdSWxShYcesmvwO3faPAjjxoX3t7kmZhGpLCIVQ/dLAe2An7IsUy3Tw/OARbluuIjy8cfQowekpcEll8Djj9vOuH2JwIoVcP31QUfinHOwezfUrw/r1wcdSWxKS4PLL4d+/awS2oABMHAgFAuzckg4i1UD3ghdZy4CjFbV8SLyMNYkHwfcJiLnAbuB9cBV4Ww8KQleegnq1oXeveG++6wX8ssvQ/Hi4e1AYVGtmv14UbVE7ZxzQSlWDL79FsqXDzqS2LN2LVxwAUyfbnNSv/MOdOyYt3WE0yt7rqo2UtUGqnqiqj4cer5vKCmjqn1U9QRVTVbVNqr6U85r/YeIFdF4/33rgTxsGJx1lv8Sy6pYMTvlP21a0JE45wqz9HS4/34oUSLoSGLPTz9ZadLp0+GII6x2eF6TMsRQ5a/zz7ekU706TJliO7dkSdBRxZa0NHjuOTuN5JxzQdixA2rU8LOaWX35peWtX3+Fxo2tElpy8sGtK2YSM8BJJ8HMmbYzS5bYTk6dGnRUsaNcOTuz4JOQO+eCsm4d3HyzX1LL7NVXoX172LTJGplTptjlx4MVU4kZ/mn+d+pkp7PPPNMn3s5sxw4bpJ6amvuyzjkXSatXW5lgn3PZZGTAPffAddfZmcy77oIxY/I/mUfMJWawC+YffAC9elmX/CuvtOoy/maw6zoffmj/R845V5CqVbN54n3OZdi2Dbp0gf797SzmkCF2PxL/NzH731u0qI2RGzzY7v/vf3DZZXadtbA78kj7f9kZO4XAnHMJ7rffrGXop7DtzEGrVnZpsUIF+PTTyA5njdnEvMfNN8P48XZ9ddQoaNvWipIUZiKwcSNea9w5V2CqVIFrrgk6iuDNnQvNmsF338HRR8M339gl10iK+cQMdlF9+nRrKX7zjf2nLFwYdFTB2jNcwU/vO+eibd06mDcPTj016EiCNWECtGgBy5dD8+Z2Wv9f/4r8duIiMYNVmZk5E5o2hd9/t/+Uzz8POqpgXXQR/PBD0FE45xLdL7/AJ58EHUWwBg+Gc8+1jrddu8KkSXYWIRriJjEDVK0KKSnWK3DzZjjnHLvgXlh9/LGNl3POuWjJyLAGUb9+QUcSjPR06NnTal1nZEDfvvD221CyZPS2GVeJGaw62KhR0KeP/YfdcIOV80yP3KxjcaN4cXj+eTvN75xz0TBkiCWjwmjLFujc2WpdJyXZ0N1+/aLfAS7MktqxpUgReOwxOO44mwTj6adtEuq33sr/+LF406SJXXt3zrlouO66wtnRdPlyO3X94482g9bYsXD66QWz7bhrMWd29dUwcSIccoiN7T39dFi1KuioClaLFjacbNmyoCNxziWajz+2ySoOOyzoSArW7NnWyfjHH6FOHevfVFBJGeI8MQO0aWM9tY89Fr7/3q6FzJkTdFQFa+xYL13qnIu8okULXwngDz6wJLx6tU0c9M03ULt2wcYQ94kZbNrIGTPgtNNg5Upo2dLGPhcWt9wC3bv7XNbOuchZvdpm+mvaNOhICoYq/N//wYUXWlWvq66Czz6z09gFLSESM0ClSjZ8qls32LrVLtg//3zhSVZjx8KddwYdhXMuUdx/vyWmwmDXLrjxRqt1rWp9mF57LbgZtHLt/CUiJYGpQInQ8u+p6oNZlikBDAcaA+uAf6vq7xGPNhclSlivuTp1rBdhr16weLEl6GJx2c0tfG3aWIk455yLhFdfDTqCgrFxo9W8/uILGwI1fLg9DlI4LeYdQFtVTQYaAu1F5JQsy1wLbFDV2sCzwJMRjTIPRGzCi7fftkT9wgvWs27z5qAiKhgVK9rA93ffDToS51y869HDiookel3s336zamZffGHFQiZPDj4pQxiJWc2eSQaTQresJ4g7A2+E7r8HnCES7CG99FKrzFK5shUYb9GicPRcXrky6Aicc/Hu8svhqKOCjiK69pR3XrQITjjBel43axZ0VEY0jIuwIlIUmA3UBgar6j1ZXp8PtFfVFaHHvwDNVPXvLMv1AHoAVK5cufHo0aMjshM5WbWqJPfdV59ly8pwyCE7+d//5lGv3paobzc1NZWyAc3NmJpajLJld0d5G8HtX0FI1P3r1asX6enpDBw4MOhQoiZRj90e0d6/WbMOpVGjDSQlBdNBpyCO36RJVXjiiePZtasITZqs58EHF1C2bMFUqWrTps1sVW2S40KqGvYNqAikACdmeX4+cESmx78AlXJaV506dbSgbNigeuaZqqBasqTqu+9Gf5spKSnR30g2li1TbdhQNSMjutsJav8KSqLuX6tWrTQ5OTnoMKIqUY/dHtHcv507VS+9VHXr1qhtIlfR3L+MDNVHHrFcAKo33qi6a1fUNpct4DvNJdfmqVe2qm4MJeb2WV5aCdQEEJFiQAWsE1hMqFjRZgW5/nqbz7lLF3j88cTssX3kkTBrVuJfG3LORZ6I9c8pXTroSCJvxw648krrgyQCzz5rfZBisWNwrolZRCqLSMXQ/VJAO+CnLIuNA64M3b8YmBT6ZRAzkpLg5ZfhqafsoNx3H1x7LezcGXRkkZeRYcPG0tKCjsQ5Fy9Wr7ZJcRJxKtl166BdO3jzTfvR8cEHNmonVhsw4bSYqwEpIjIX+Bb4XFXHi8jDInJeaJlXgcNEZClwB3BvdMLNHxGb8GLMGChVCl5/Hc4+G9avDzqyyCpRAi67zGqKO+dcOKpVsw6zifa9sXgxnHIKTJsG1avbv+edl/vfBSmcXtlzVbWRqjZQ1RNV9eHQ831VdVzofpqqdlHV2qraVFV/jXbg+XHBBXZwqlWz7vHNm9skGImkQwfrdbhjR9CROOdi3S+/WL2HRKuJPWWKJeWlS6FRI7vMd9JJQUeVuwT7bRS+xo2te3xysv2iatbMknUiefdd+P33oKNwzsW6pCSoWTPoKCJr2DA7fb1hg9WymDoVatQIOqrwFNrEDPZGnDYNOna009lnngkjRgQdVeQMGmRV0ArjXNXOufD89ZdNl3vhhUFHEhkZGVZO9OqrrdTm7bdbyeJ4GkFXqBMzQLlyNmVkz57WEax7dyvnGVtd1w7e7bfDO+8EHYVzLlZNnAgvvhh0FJGxfbsVl3rsMZsV64UX4Jln4m+GrBjsKF7wihaF556D446D226DRx6xaxKvvWa1U+PZAw/YfNXOOZed7t2DjiAy/vrLJi+aOdMaXO++a51741GhbzFndsstNl1kuXIwciS0bQtr1wYdVf4cdpidrv/gg6Ajcc7Fmt694eOPg44i/xYssH5CM2daLYevv47fpAyemPdzzjkwfbod3D21VBcuDDqq/ClbFipUCDoK51ysueMOm8Qhnk2caPuwbJnNHT1zJpx4YtBR5Y8n5mzUr28H9+ST9519JF41bgynnWZDIpxzDmDUKLuMF8+Xul56yYaGbt5sFR0nT4aqVYOOKv88MR9A1ap2kC+6CDZtgvbt4ZVXgo7q4M2cCQ8/HHQUzrlY8fPPsVv5Kjfp6dbav+kmu9+nj3VyLVUq6MgiwxNzDkqXhtGj4d577eD36AF33RWfJetatIA33sh9Oedc4tuwwUafVKkSdCR5l5pqQ7uefdbGX7/2mvXCTqSKZQm0K9FRpIhNePHqq1bs/P/+z1rRW7cGHVne/fWXDbj3cc3OFV47dlg1rNTUoCPJu5Ur4fTTYdw4OwU/caKNV040npjDdM019iaoWNF6OLdqBatWBR1V3lSpAk8/HX9j+pxzkVOiBMyfH18FNwB++ME6d/3wAxx7rHXObd066KiiwxNzHrRpAzNm2Jti9mzrsf3jj0FHFT4R69j24oteQ9u5wujXX23626SkoCPJm48+sg6sq1bZvzNmQN26QUcVPZ6Y86huXXtTtGwJK1bYtdt4GgcoYteXNm4MOhLnXEGrWtXmJI4Xqlb8qXNnu3zYrRt8/jlUqhR0ZNHlifkgVKpkw6e6dbM3y3nnwYAB8VPG8777rPfitm1BR+KcKyhLl8KiRdaoiAe7d1vRp9tvt+/Whx+G4cPtVHyi88R8kEqUsDdJv37WS7tnT/jPf+zNFA/uvBO+/DLoKJxzBeXXX+H774OOIjybN0OnTnbZrUQJePttKy8cr8O78irXWtkiUhMYDhwOKDBEVZ/Pskxr4EPgt9BT7++ZtzmRidiQg9q1rWfg4MFWxGPUqKAjy93LLyfW8ALn3IFt3QpnnRV0FOH5888StGhhHdQqVbJJhuK9OllehfPVvBu4U1XrAacAt4hIvWyWm6aqDUO3hE/KmV12GUyaZG+iTz+1685//hnb51uKFLHe5U88EXQkzrlo69kT3n8/6ChyN3Mm3HxzY+bPh+OPt8eFLSlDGC1mVV0NrA7d3yIii4AaQJxXkI6sFi3sTdSxo/3Su/nmxhxzjHXvj1VNm0LDhkFH4ZyLtniY1vG992ymq7S04pxxhj2uWDHoqIIhmoceSyJSC5gKnKiqmzM93xoYA6wAVgG9VXVBNn/fA+gBULly5cajR4/OR+ixKTW1GA8+eALff38IxYunc999P9GqVexOUbVpUzHmzatIy5Z/5+nvUlNTKRtvAyHzIFH3r1evXqSnpzNw4MCgQ4maRD12e+Rl/1Rh4MDaXHbZH1SqtDPKkR0cVXj77SMZOvQYAM466w/uuus3ihWLk960edSmTZvZqtokx4VUNawbUBaYDVyYzWvlgbKh+x2AJbmtr06dOpqodu5U7dhxpdpbTvWJJ1QzMoKOKnurVqnee2/e/y4lJSXiscSSRN2/Vq1aaXJyctBhRFWiHrs98rJ/GRmqY8eq7toVtXDyZccO1auvtu9JEdX+/VUnTUoJOKroAr7TXPJjWN1/RCQJaxG/par7XalQ1c2qmhq6PwFIEpEEH2l2YElJcOedi+nf3zqI3XsvXHcd7IzBH6zVqlnJ0U2bgo7EORdJqjbmt3NnKycca9avtzmTX3/dhm+OGWNzERSWntc5yTUxi4gArwKLVPWZAyxTNbQcItI0tN51kQw03ojYm2zMGHvTvfaazVC1YUPQke1vxw673rxlS9CROOciZe1aGDEiNusrLF0KzZv/M03j1KlwwQVBRxU7wmkxtwC6A21FZE7o1kFEbhSRG0PLXAzMF5EfgQFA11CTvdC74AJ701WtCikp9mZcujToqPZVogTMmwflygUdiXMuEtLT4dBDrdZCrA2LnDbNyhkvXgwNGsCsWdAk5yuuhU6uh0xVv1JVUdUG+s9wqAmq+pKqvhRaZpCqnqCqyap6iqp+Hf3Q40eTJvbma9DA5kA95RT46qugo9pX8eLWwp89O+hInHP59fHHVhM71owYAWeeaaexO3Sw78GaNYOOKvbE2G+pxFWzpr0JO3SAdevgjDPsTRpLunSB444LOgrnXH6dey48/3zuyxUUVXjwQRsOtXOnVUn88EM/S3cgnpgLULly9ma87TZ7c3bvbm/WWDnp37SpzXc6Y0bQkTjnDtZLL9m12/Llg47EpKXB5ZdbresiRWxegQEDYrNDWqzwxFzAihWzX7IDB9qb9OGH7U2blhZ0ZGbZMqup65yLT40aQa1aQUdh1q61s4MjR9r8zx99ZK1llzP/zRKQW2+FY46Bf//b3rTLllmJzMqVg42rfXv7d906OOywYGNxzuXNpElWwrJkyaAjsZmsOnaE336zS3njx1s/G5c7bzEHqEMHmD7d3rRff209FRctCjoq6zXeqVPsnGJ3zuVOFYYNi41hj19+aSNQfvsNGje2csWelMPniTlgDRrYm/bkk+1N3Lx58NMx1q5tQxp8oL9z8WPHDhseFfRZt6FD7czbpk02XHTKFCtk5MLniTkGVKtmnTUuusjezO3bwyuvBBtTkSL2ofrzz2DjcM7l7vffbSKdIM9yZWTAPffYMK3du+Huu20iijJlgospXnlijhGlS8Po0fbG3r0bevSwN3ZGRjDxFClipUQrFdrCqs7Fj1q17Md9UGe5tm2z4Zb9+1sH1yFD4MknY6+4Sbzw/7YYUqSIzY88dKi9uZ96Ci6+2CY5D0KzZnYa6uefg9m+cy53Y8fCq68GNyZ49Wpo1crme65Qweakj8XiJvHEE3MMuvZa+Owzm4t07Fh7069aFUwsq1ZZD23nXGw66aTgSlrOnWs/4L/7Do4+Gr75xoZHufzxxByj2ra1N/kxx1iZzGbN4McfCz6O7t2thKhfa3Yu9kycaNdwk5MLftsTJth17eXLbYjWzJnwr38VfByJyBNzDDv+eHuzt2gBK1ZAy5ZWA7egffYZ3H9/wW/XOZezadNg48aC3+6gQVb2MzUVLr3URpIE3Rs8kXhijnGVKsEXX8Bll9mH4LzzrGpYQYqFXuLOuX2tXw+PPGLDGwtKerqVFP7Pf6xjat++8NZbsVHQJJF4Yo4DJUvahBcPPWQfhj0fjN27C2b7IlYytGXL4DqiOef+sX49nHYa7NpVcNvcsgU6d7aGQfHi8Oab0K+f1zuIhlwTs4jUFJEUEVkoIgtEpGc2y4iIDBCRpSIyV0ROik64hZeITXgxYoR9KAYNstbz5s0Fs/3Spa3V7GMSnQveoYfCnDmQlFQw21u+/J9LaYcdZmfxunUrmG0XRuG0mHcDd6pqPeAU4BYRqZdlmXOA40K3HsCLEY3S7XX55VYPt1Il+OQT+7D88UfBbPtf/4I33oCffiqY7Tnn9vfVV5V4+OGCS8rffWczz82dC3Xq2Oxzp51WMNsurHJNzKq6WlW/D93fAiwCamRZrDMwXM0MoKKIeBG2KGnRwj4cxx8P8+bZh+bbbwtm22XLFsx2nHPZO+mkDfz73wWzrbFj4fTTbVRG69Y2UqQgr2kXVnm6xiwitYBGwMwsL9UAlmd6vIL9k7eLoGOPtYkv2raFv/76Z4B/tF10ERx5JPzxR+nob8w5t4+33oKNG5OoWze621G1AkcXXQTbt8PVV9vojEMPje52nQl72kcRKQuMAXqp6kFd2RSRHtipbipXrszkyZMPZjVxITU1tUD2r08foWTJOkyYUI2LLoIePX6ha9flUe2QMWvWocyadShHHjk5ehsJWEEdv4K2ceNG0tPTE3Lf9kjUYwcwe3Z16teP7v7t3i0899xxfPxxdQCuv/5XLr30D77+Omqb3EciH7+wqWquNyAJ+Ay44wCvvwxcmunxz0C1nNZZp04dTWQpKSkFtq2MDNX+/VXtd67qtdeq7tgR3W2mpKREfRtBKsjjV5BatWqlycnJQYcRVYl67ObNs3+juX8bNqiecYZ9j5QsqTp6dNQ2dUCJevz2AL7TXHJuOL2yBXgVWKSqzxxgsXHAFaHe2acAm1R1dX5/NLjwiMBdd8GYMVCqlNXNPecc2LAhetvcsaMIycmxMferc4nu779tmGQ0h0j++us/084efrhNitGlS/S25w4snGvMLYDuQFsRmRO6dRCRG0XkxtAyE4BfgaXAK8DN0QnX5eTCC23SiapVred28+bwyy/R2VaJEhl8/XVwhfOdKyzS022I0qRJNrlNNHz9tZXe/eknOOEEqzjYrFl0tuVyl+thVtWvgByvWIaa57dEKih38E4+2T5UnTpZj+1mzeCDD2xYVaQdcgg8+6x9kM86K/Lrd87BsGH2A/uxx6Kz/pEjrXPXjh1w9tkwapTNEuWC45W/EtCRR8JXX9np7HXrbLaXt96KzrZOPx0aNIjOup1zcNVV0Lt35NeraiU9L7vMkvJNN8H48Z6UY4En5gRVvjyMGwe33go7d1qVnocesg9jJDVubNe4x42L7Hqdc3D77fD775EfprRjB1x5pdW6FrEzX4MHR+9UucsbT8wJrFgxq2s7YAAUKWJ1bbt1s7rXkbR9u1UFcs5F1llnwRFHRHadf/8N7dpZresyZeDDD6FXL695HUs8MRcC//mPtWjLloW334Yzz4S1ayO3/lq14L//tV6dkW6RO1cYbd1qn9VzzoESJSK33p9/tk5e06ZB9er277nnRm79LjI8MRcSHTvadecjjoDp0//pgRkpqnDttbBsWeTW6VxhtXZt5EdUTJ78z0iNRo1g1iz718UeT8yFSHKyfRgbN7bW7Smn2JjFSBCx4Ry1atnwDufcwVm1yoY8PvBA5Nb5+ut2WnzDBpuVbupUqOFFk2OWJ+ZCplo1G+t8wQWwaRO0bw9Dh0Zm3SK2rgcfjMz6nCuMhgyBd96JzLoyMuC+++Caa2zu5jvusJr6PhlNbPM+eIVQmTLw3nvQpw/07w/XXw9LlsDjj1snsfy45BLv2encwUpPj9zoie3bref1u+9C0aI2h/uNN+b+dy543mIupIoUgSefhFdesUTav7+V39u2LX/rLV/efpnv+YXunAvP1q3QsKF9BvPbQ/qvv6BNG0vK5cvDhAmelOOJJ+ZC7rrr4NNPrajA++/b9JGr81nlvHx5O1VetGhkYnSuMChTxvp8lM7njKrz51vFv5kz4aijrLOnV+aLL56YHWecYROgH3MMfPedfah//PHg1ydiQzC++MJOkTvncvb++3ZtuUqV/K3ns8+gRQsbHbEnOZ94YmRidAXHE7MD4F//ghkz4NRTYflyq609YUL+1vnnn1YS1DmXs6ZNbZREfrz4og2L3LzZLkulpNgsUS7+eGJ2e1WubKfSLrsMUlOt1Tto0MGv74or7Atn3rzIxehconntNTuNfbA159PTrbf1zTfb/fvus17dpUpFNk5XcDwxu32ULAkjRtiQp4wMqxqWn3lgf//dxmN6RTDn9qdqp50Ptj9GaqpN9/rss5CUZOOVH300/6MrXLD88Ln9iNiQjREjoHhxq7fduTNs2ZL3dR1zjE07uX27J2fnMtuyxUpk9utnHSbzauVKm91t3DibgnXiRJuJysW/XBOziLwmImtEZP4BXm8tIptEZE7o1jfyYbogXH65ndo+7DC73tyyJfzxx8Gt64orrCSgc87Mnm3DFQ/GDz/YZaIffoData1/SOvWEQ3PBSicUhDDgEHA8ByWmaaqnSISkYspLVtaz86OHW0GqWbN4KOP8r6eN96w62jOOdi40RLpwSTT6dMP47HHbLzzaadZj+5KlSIcoAtUri1mVZ0KrC+AWFyMOvZYG07Vpo31tD79dJg6NW/fBGXK2K/77t2jFKRzcaRzZ1i4MG9/o2rXkh944ES2bbPP0uefe1JORKJhXPgTkVrAeFXdb0SciLQGxgArgFVAb1VdcID19AB6AFSuXLnx6NGjDzbumJeamkrZBCtIu2uX8Oyzdfjkk2oA9OjxC127Lg+7StHu3cLKlaU46qh8lhcrAIl4/AB69epFeno6AwcODDqUqIn1Y6dqn6XixcPvdJGeLgwYUJtx42zmiWuu+Y1u3ZYl5BzKsX788qtNmzazVbVJjgupaq43oBYw/wCvlQfKhu53AJaEs846depoIktJSQk6hKjIyFB94glV+3pRve461Z0787aOfv1UlyyJTnyRkqjHr1WrVpqcnBx0GFEVy8du6lTVK67I299s3Kh61ln2eStRQvWBBxZEJ7gYEcvHLxKA7zSX/Jjv6QZUdXOm+xNE5AURqaSqf+d33S72iMA990Ba2nyeeOJEhg61KSTfe896hoajcWMrAepcYXPqqVCzZvjL//47dOoECxZYnYEPP4QdO9YA9aIVoosB+R4uJSJVReyEiog0Da3T6z0luFat/mbKFKssNGmSfeGEO7F7x442Rvr996Mbo3Ox5I477DNSq1Z4y8+caZ0tFyywynwzZ0Lz5lEN0cWIcIZLjQS+AeqKyAoRuVZEbhSRPXOVXAzMF5EfgQFA11Bz3SW4pk1h1iyoXx9++slKCk6fHt7fpqXBokXRjc+5WHL22XDkkeEt++671mN7zRo480z4+ms4+uiohudiSK6nslX10lxeH4QNp3KF0JFHwldfQdeu8Mkn0LatVR+67LKc/+6oo+D++22yjLp1reKYc4not99g2jQby58bVXjiCSurCTZX+uDBVtXLFR4xO6X95s2bWbNmDbvidFLfChUqsCiBm4RZ9+/555M47bQq3HdfeS6/3GaV6ts393llX3rJ5m4++eQoB+xcQHbuDK/k5s6dcMMNMGyYfW6eespOfydiz2uXs5hMzJs3b+avv/6iRo0alCpVConDd+aWLVsoV65c0GFETeb9U1W2b9/OxRevpEYNuPrq8jz0kCXnoUNzbg2/+KL9++efULVq9ON2riB98YUV6albN+fl1q+3mtdTpth8zG+9BeefXyAhuhgUk7Wy16xZQ40aNShdunRcJuXCRkQoXbo0NWrU4NRT1zBuHJQta18uZ54Ja9fm/Pc//2ynwr1ngkskqjB6NPydy/iUJUusU9eUKVCtGkyd6km5sIvJxLxr1y5K+ZxlcadUqVLs2rWLjh3tuvMRR1hnsFNOsc5hB1K3rtXk3r3bems7F+82bbKzQEOG2OfgQKZNs8/H4sWQnGw9rxs3Lrg4XWyKycQMeEs5DmU+ZsnJ1mO7cWMb59y8uQ2rOpCiRaFXLxgzJvpxOhdtX3xhs7Ll5M034Ywz7DR2x46WpPMyxtklrphNzC7+Vatmp+fOP9+K9p99Nrz66oGXf/RRuPhiP6Xt4tv69XDRRfZ+zo6qdYy84grYtcvmO//wQ0jgLikujzwxu6gqU8ZawXfdZaeqr7sO7r03+1PWFSvChg02fnPnzoKO1Ln8277dJnnZvDn73tRpaTad6iOPQJEi1qp+/vnwem27wsMTs4u6IkWgf3+73lasGDz5JFxyiU1bl9Whh8LLL0Px4gUfp3P5sXu3jUD4/nsoX37/19eutXH+I0da58jx4+HWWws+Thf7PDFHWOvWrbk1n5+2SKwjNxs2bODwww/nlzDqaHbp0oWnn34639u8/norQlKhgrWiW7eG1av3X+7446329uDB+d6kcwXm4YdteGB2PyoXLbLymt98Y9eRp0+Hc84p+BhdfPDEXEg99thjdOjQgWOPPTbXZfv27cujjz7Kpk2b8r3dM8+0L6ejj4Zvv7Uvq3nz9l/u5JPtmrRz8UDVJne5NJs6iV98YZ0ff/vN3tczZ0KDBgUfo4sfnpgLkZ2hC7fbtm1j6NChXHvttWH9Xf369TnmmGMYMWJEROL4179gxgz7slq+HFq0sJZ0ZkcdBccea192uY0DdS5IS5ZAhw5WGCTrNMKvvALt29vwqYsugsmTrVOkcznxxBwFGRkZ9OvXj0qVKlGlShV69+5NRqi3U3anqa+66io6deq0z3O7d++mZ8+eHHLIIRxyyCHcdddde9cBVm2rf//+HHvssZQqVYr69evvlzhbt27NTTfdRO/evalcuTItWrQAYMKECYjI3scA/fv3R0T2u/Xt2xeA8847j5EjR0bs/6hKFRs+1bUrbNliU9tlPXUtAo0aQYkSEduscxFXuzYMGLBvZ6+MDLj7bujRA9LT7Qfm6NGWvJ3LTdwkZpFgbgfjrbfeomjRonz99dcMGjSI5557jlGjRuV5HRkZGXzzzTe8/PLLDBkyhOeee27v6//973959dVXGTx4MAsXLqRPnz7ccMMNfPzxx/usZ8SIEagq06ZNY/jw4QBMmzaNxo0b7zPu+KabbmL16tV7b3feeSdVq1blilDl/aZNmzJr1iy2b99+cP8p2ShZEt5+24aOZGRYR5iePe2LbI+uXa218fLLEduscxFz1VVWue644/55butWG/b31FPW2XHoUJuYokjcfNu6oMVkrex4V69ePf773/9Srlw56tSpwyuvvMKXX37JpdldgDqAatWqMWDAAESE448/nsWLF/PMM89wxx13sHXrVp555hkmTpzIaaedBsDRRx/NrFmzGDx4MB07dty7nqOPPnq/jlvLli2jevXq+zxXrly5vbWvn3zySUaOHMnkyZOpXbs2ANWrV2fXrl2sWrUqrOvS4RKBfv3si+3aa63l8csv1nN1z7jOEiWsx6tzsebmm63FvMeqVXDeeTB7tg3/GzPGemI7lxdx8xtONZjbwWiQpWdH9erVWbNmTZ7Wccopp+zTom3evDkrV65k8+bNLFy4kLS0NNq3b0/ZsmX33l588cX9elk3zqa+3/bt2yl5gJklHn/8cQYOHEhKSgp1M1Xe31MiNZIt5sy6dbNOMocdBh9/bIX/ly+31ypXhltusetzCxZEZfPO5cn48dYSbtrUWsVgU5g2a2ZJ+ZhjrJOjJ2V3MHJtMYvIa0AnYI2qnpjN6wI8D3QAtgFXqer3kQ40niRlmTxVRPZeHy5SpAiaJePndWrLPev66KOPODLLzOtZt12mTJn9/r5SpUps2LBhv+f/97//8dJLL+3TUt5j/fr1AFSuXDlPsebFaadZp7COHWHuXPvS++gjaNLEXv/zT58Cz8WG+vUh80mnjz+2yy6pqdaZcexY+0Hp3MEIp8U8DGifw+vnAMeFbj2AF/MfVuKqXLkyq7MM3v3xxx/3W27mzJn7JPAZM2ZQvXp1ypcvT7169ShRogTLli2jdu3a+9yOOuqoXGNo1KgRCxcu3Oe5hx9+mCFDhjBlypT9kjLA/PnzqVGjBocffni4u3pQate2lkabNpaITz/dvuTAvvhOP91OD2a+Du1cQVm3zuZIrlkTTjrJnhs40E5fp6bCZZfZmR9Pyi4/ck3MqjoVWJ/DIp2B4WpmABVFxAcEHEDbtm355JNPGDduHD///DN33HEHy/ecs81k1apV9OrVi59//pn33nuPp556ittvvx2w68G9e/emd+/evPbaayxdupQ5c+bw0ksvMWTIkFxjOPvss1m0aBHr1q0DrKU8YMAA3nnnHcqUKcOff/7Jn3/+SVpa2t6/mTZtGmcX0MDiQw+FTz+Fq6+2EocXXWQdaVQtIX/5pdXedq6glS5tp6uLFLF+D//5j9W6zsiAhx6CESNynn/cuXBEovNXDSBzZlkRem6/mk4i0gNrVVO5cmUmT56c7QorVKjAli1bIhBawUtPT2fnzp2kp6fv3Yddu3axe/dutmzZQpcuXfjuu++4+uqrAbj++uvp1KkT69at27t8eno6l1xyCdu3b6dZs2aICN27d+e6667bu8zdd99NhQoV6N+/PzfddBPlypWjQYMG9OzZc5/17Ny5c7//y1q1atG4cWOGDRvG9ddfz1NPPcXmzZv3GT4FMG7cOFq3bk1aWhpjx47l/fff32fd2R2jtLS0Ax7XvOreHYoVO5JXXjmGu++GKVNW0avXEi65RPn22yIsWFCexo03RmRbWaWmpkZsP2LJxo0bSU9PT8h92yNax27kyJqcccYaDj98BxMmFOXhh+sxc+ZhJCVlcNddP9Gq1RqmTIn4ZveTqO/NPRJ9/8KiqrnegFrA/AO8Nh5omenxl0CT3NZZp04dPZCFCxce8LV4sXnz5qBDyNEnn3yiderU0d27d+e67KBBg7Rdu3b7PHeg/YvGsXv3XdWSJa073hlnqG7YoLpkiep//hPxTe2VkpISvZUHqFWrVpqcnBx0GFEVjWOXkaH6+uuqmzapLlumWr++vR8PO0x12rSIby5Hifre3CPR9w/4TnPJj5Holb0SyDyL6BGh51wMa9++PbfccgsrVqzIddmkpCQG5ja5bBRdfLFNH3n44XYau3lzO5U4YICVOVyyJLDQXCHw2Wf2vrvqKli8+J8ysnXrWnnNli2DjtAlmkicyh4H3Coi7wDNgE2qms3UBC7W3HbbbWEt16NHjyhHkrumTe1LsFMnmD/fvhw//NCScpEi+xZ4cC6SSpe2aRnff9+G9W3fbp0Tx4yBQw4JOjqXiHJtMYvISOAboK6IrBCRa0XkRhG5MbTIBOBXYCnwCnBz1KJ1hdpRR9msPO3bW/3stm1tJp/u3eGrr2yuW+ciZflymyu5ZUt7f110kSXla66xzomelF205NpiVtUcy1WFzpnfErGInMtB+fI2trlnT3jhBRuesmQJ/PWX9eauVy/oCF2iKFbMpijt0cOKiYCV1rz7bh9P76Irbip/ObdHsWIwaBA895x9QT74IGzebNWWJkw4+IptzgHs2mVzK6va8KehQ20I1Hvv2WQUnpRdtHmtbBeXRKzVfMwxNgfuiBFWY7tmTWjVCrIpeOZc2NLT7VLJzz9bp8Nx46yfg3MFwROzi2vnnmvX/zp1sopha9bYl+natVBA9VBcAnnkEbsc8sIL1o+hfn27dBJGQT3nIsZPZbu417AhzJplJRJ/+QVat4ZhwwIOysWlv/+2fgt//22dDL/6ypOyK3iemF1CqF4dpk6Fzp1hyxa7HvjYY5CSEnRkLh688AJccYWNjd+506Zz/Ogj62zoXEHzxOwSRpkyNra0d2+rY3z//fDMM1bH2LkD2bHDkvCbb9qY+Oeft86FxfxCnwuIJ2aXUIoWtQkvXn7Z7o8fb9PwTZsWdGQuFo0YAccfb+OSy5SxojW33eY9r12wPDFH2AUXXMAhhxxC9+7dgw6lUOvRAz75xMahzpgBN91k00g6t8dPP8EDD8Dvv0ONGv90InQuaJ6YI6xnz54MHz48z3+3fPlyWrduTb169WjQoAHvvvtuFKIrXNq1g6+/hlq1YMECaxl98EHQUblYMGgQNGhgSfmkk6zzYMOGQUflnPHEHGGtW7emXLlyef67YsWK8dxzz7Fw4UImTpxIr1692Lp1axQiLFzq1bMa282bw6ZNVr7z00+DjsoFacgQ6NXLCol07mydBqtXDzoq5/7hiTlGVKtWjYahn+xVq1alUqVKrF+/PtigEkSVKjBpEnTtCqmpcM450K9f0FG5gpaRYb2tb7jBCoj07m2dBb0YjYs1nphj0OzZs0lPT6dmzZq5L+zCUrIkvPWWXVMEeOgh6+STnh5oWK6AbN9uxWhefNF6Xr/8snUSLFo06Mic258n5hizfv16rrjiCoYMGRJ0KAmnSBGrgTx8uA2FGTjQWs9btgQdmYumP/+0nvkTJkC5cnYpIwZmMnXugDwxF6D+/fsjIvvd+vbtC8COHTs4//zzuffeezn11FMDjjZxde9uE99XrAiff25zOy9fHnRULhrmzbNOXj/8YBW8ZsywToHOxTJPzBF25pln0qVLFyZOnMgRRxzBN998s/e1m266idWrV++93XnnnVStWpUrrrgCVeWqq66ibdu2PtSqAJx+Onz7LdSuDYsWwcknw+zZQUflIumzz+DUU61u+sknW89rnxbUxYOwErOItBeRn0VkqYjcm83rV4nIWhGZE7pdF/lQ48MXX3zB2rVr+euvv1ixYgXNmzff+1q5cuWoWrUqVatW5Y033mDkyJFMnjyZ2rVrM336dEaNGsUHH3xAw4YNadiwIfPmzQtwTxJf7drWY7tVK5vP+dRTYezYoKNykTBggF2mSE2Ff/8bpkyxToDOxYNci86JSFFgMNAOWAF8KyLjVHVhlkVHqeqtUYgx4Tz++OMMHjyYlJQU6tSpA0DLli3J8NqRBe7QQ2HiRLjmGuscduGF1imoceOgI3MHIz0dBg06ljFj7PG998Kjj1r/AufiRThv16bAUlX9VVV3Au8AnaMbVvYeeshuAHXqwOLFdvpxz5fonXfC00/b/erVYdUqmDzZZhsC6/Cxp09VuXLW6eejj6y3JtisMm+/bfcPpiRf5uvG5cuX3+9aMsD//vc/Bg8ezOTJk/cmZRes4sWtTvJjj9nju+6C/v3rsGtXsHG5vElNhfPOgzFjalKsGLzxBjz+uCdlF39EVXNeQORioL2qXhd63B1olrl1LCJXAY8Da4HFwO2qul93GhHpAfQAqFy5cuPRo0dnu80KFSpQu3btg9mfQK1YsYIePXqwdu1aihYtyj333MMFF1yw9/UnnniC4cOHM378eI455pgAI82/9PR0imYz1mTp0qVs2rQpgIgiY9Kkygx/tCzpGUWoclIZ+vVbSNmyu4MOK2J69epFeno6AwcODDqUiFq1qiR9+tQn44/1lCq5i1ue2ERycvy+D3OSmppK2bJlgw4jahJ9/9q0aTNbVZvkuJCq5ngDLgaGZnrcHRiUZZnDgBKh+zcAk3Jbb506dfRAFi5ceMDXYtmqVav0hx9+UFXVJUuWaPXq1TU1NVVVVR955BE97LDDdPr06bp69eq9t+3btwcY8cHbvHlzts/H67HLbMYM1YoVdyio1qmj+ssvQUcUOa1atdLk5OSgw4ioiRNVK1ZUBdXjjlN9880ZQYcUVSkpKUGHEFWJvn/Ad5pLfgznJM9KIHOliyNCz2VO7utUdUfo4VCgUF6hy1y96/DDD99bvUtVeeqpp1i3bh0tWrSgWrVqe2/Tp08PNmi3n2a/j2L8Ff2pW9culyQn2yxVLraowpNPwtlnw8aN0KEDzOkzikaLPw46NOfyJZzE/C1wnIgcLSLFga7AuMwLiEi1TA/PAxZFLsT49MMPP+yt3iUibNq0KdtfRmeccUbQobqsXnyRE6a8x8yZNttQaqr1Q7j/fq8UFitSU6FbN+vcpQp9+lh/kdJvvEiNceNyX4FzMSzXxKyqu4Fbgc+whDtaVReIyMMicl5osdtEZIGI/AjcBlwVrYDjwfr167nhhhu8elecq1DB5ud94gnrDPjYYzb+ec2aoCMr3ObMsaIhb78NpUtbvevHHvNOXi5xhPVWVtUJqlpHVY9V1UdDz/VV1XGh+31U9QRVTVbVNqr6UzSDjmV7qnfdfvvtXr0rARQpAvfcY5XCype3aSSTk+GLL4KOrPBRtfHJTZvCb7/ZOPRvv7Uhbs4lEv+NGUGaqXrXpZdeGnQ4LoLatLEKYS1bWu3ldu3gjjsgLS3oyAqH9evhoougZ0+brvGGG2DuXK/k5RKTJ+YIyly9q0WLFl69K8FUrw4pKTZDVZEi8Oyzlhjmzg06ssT20Udw3HFWla18eRg9Gl56CUqVCjoy56Ij18pfLnyZq3dt2bKFcuXKBRyROyjvvceC6dNpkc1LxYrZDFWdOsEFF9gp1SZNLFnfey8kJRV4tAlrwwa4/nr2VvFKTrbkfPTROfxRDsfOuXjhLWbnsqpUiV0VKuS4SNOmNpTqhhvs1GrfvpagZ80qoBgT3EcfwQknWFJOSoJnnrEqfzkmZQjr2DkX6zwxO5fVsGFU/fTTXBcrU8ZOqU6caFMKzp1rU0j27OlzPB+s33+H88+30pqrV0Pz5jB/Ptx+O2RTaG5/YR4752KZJ2bnssrjl3u7drBwoSVkEes5fNxxMGIE+Lwk4UlLgwcftBr4H35o14/794dp0+y5sHlidgnAE7NzEVC6NDz3HHz/vU2q8tdf0L27tfi+/jro6GKXql03rlfPrt3v2mXTNC5ZYpOJhNVKdi7BeGJ2LoIaNrQ5nl97DapWtWvOLVpA167wyy9BRxdbJk+2Hy4XXmid6OrVg0mT4J13oEaNoKNzLjgxm5g1l1mvXOzxY2aKFoWrr7ZW3913Q4kSMGqUnd6++mpYujToCIM1eza0b29jw2fOhMqV7WzDnDn2nHOFXUwm5qSkJLZv3x50GC6Ptm/fTpKPF9qrbFmbZGHJEmsxi8CwYXbNtGtX69VdWKha9bQ2baz3+mefWee5Bx+EX3+16/P+1nHOxGRirlKlCitXrmTbtm3eCosDqsq2bdtYuXIlVapUCTqc/JswgblPPBGx1dWsCSNHWiK++mp7btQoqFsXWre2Xt2J+jbfvdsKgtSrB2eeaaevixeHO++EZcvgoYfsB0zERPjYOReEmCwwUr58eQBWrVrFrl27Ao7m4KSlpVGyZMmgw4iarPuXlJTE4YcfvvfYxbXSpcmIwrE79li79vzAAzbpwrBhMGWK3WrWtM5OV1xhk2fEu19/haFD4cUXbUpGsP26+2646SY45JAobThKx865ghSTiRksOcfzl/zkyZNp1KhR0GFETULv3wsvUH3xYmvORsHRR8Mrr1hyfuUVGDQIli+H226zlmS7dla4pH17a13Giy1bbN7qQYP27Yl+7LHQuzdceWUBlNGM8rFzriDEbGJ2LjCjR1NlTzMviipXhvvus5byBx9Y6zIlBSZMsFvp0nDZZTYX9Bln2DXZWLNhg1Xpeu89i3nPfNXFisGll1pJzZYt7fp6gSigY+dcNIWVmEWkPfA8UBQYqqpPZHm9BDAcaAysA/6tqr9HNlTnElNSEnTpYrfly+169LBhNpvV0KF2K1bMkvM551hj8MQTgxnjm5YGM2bA55/D1KnWMs5cRKVZM+jWDS6/PIqnq51LcLkmZhEpCgwG2gErgG9FZJyqLsy02LXABlWtLSJdgSeBf0cjYOcSWc2adh327rutxOeHH1rnqfnzrSfzZ5/ZcqVLW3Ju1856OR9/vJ0yjmTP5p07raLZDz/YUKbp02HePHt+DxE4+WTr1Hb++VCtWuS271xhFU6LuSmwVFV/BRCRd4DOQObE3Bl4KHT/PWCQiIh6l2rnDlqDBnZ74AFYs8aS8tixliR/+82Kl2SeNKNoUTj8cKs8VrmyJcmqVaFKFZsusVgx64i1dWsxvvkGtm6168J7bitX2npXr7bW+rp1/5yazhrX6afDWWfBaadBxYoF9B/iXCEhueVOEbkYaK+q14UedweaqeqtmZaZH1pmRejxL6Fl/j7QekuXLq1NmzaNwC7Epo0bN1Ixgb+xEnr/5sxh9+7dFGvSJOhIDmjnTti82W6bNsGOHXbL3ZzQvw3D2k6pUlCypCXfsmWhXLkYH28cB8cuvxL6s0fi79+UKVNmq2qOb9AC7fwlIj2AHqGHO6ZMmTK/ILdfwCoBB/xhkgASf/+mTEnU/asE4e3b9u1227Ah2iFFVCIfOygMn73E3r+6uS0QTmJeCdTM9PiI0HPZLbNCRIoBFbBOYPtQ1SHAEAAR+S63Xw3xzPcvviXy/iXyvoHvX7wrDPuX2zLhVP76FjhORI4WkeJAV2BclmXGAVeG7l8MTPLry84551ze5dpiVtXdInIr8Bk2XOo1VV0gIg8D36nqOOBV4E0RWQqsx5K3c8455/IorGvMqjoBmJDlub6Z7qcBXfK47SF5XD7e+P7Ft0Tev0TeN/D9i3eFfv9y7ZXtnHPOuYITk7NLOeecc4VVTCRmEblTRFREKgUdSySJyCMiMldE5ojIRBGpHnRMkSQiT4nIT6F9HCsiFYOOKVJEpIuILBCRDBFJmB6iItJeRH4WkaUicm/Q8USSiLwmImtCdRUSjojUFJEUEVkYem/2DDqmSBGRkiIyS0R+DO1bv6BjigYRKSoiP4jI+JyWCzwxi0hN4Czgj6BjiYKnVLWBqjYExgN9c1k+3nwOnKiqDYDFQJ+A44mk+cCFwNSgA4mUTOV1zwHqAZeKSL1go4qoYUD7oIOIot3AnapaDzgFuCWBjt8OoK2qJmPVb9qLyCnBhhQVPYFFuS0UeGIGngXuBhLuYreqbs70sAwJto+qOlFVd4cezsDGuCcEVV2kqj8HHUeE7S2vq6o7gT3ldROCqk7FRoUkJFVdrarfh+5vwb7gawQbVWSoSQ09TArdEur7UkSOADoCQ3NbNtDELCKdgZWq+mOQcUSTiDwqIsuBy0m8FnNm1wCfBB2Ey1ENYHmmxytIkC/2wkZEagGNgJkBhxIxodO8c4A1wOeqmjD7FvIc1gjNyGW56JfkFJEvgKrZvHQ/cB92Gjtu5bR/qvqhqt4P3C8ifYBbgQcLNMB8ym3/Qsvcj51me6sgY8uvcPbNuVgjImWBMUCvLGfl4pqqpgMNQ31VxorIiaqaEP0FRKQTsEZVZ4tI69yWj3piVtUzs3teROoDRwM/is2ifgTwvYg0VdU/ox1XpBxo/7LxFjYWPK4Sc277JyJXAZ2AM+Kt2lsejl2iCKe8rothIpKEJeW3VPX9oOOJBlXdKCIpWH+BhEjMQAvgPBHpAJQEyovICFXtlt3CgZ3KVtV5qlpFVWupai3stNpJ8ZSUcyMix2V62Bn4KahYokFE2mOnZs5T1W1Bx+NyFU55XRejxFowrwKLVPWZoOOJJBGpvGdUh4iUAtqRQN+XqtpHVY8I5bquWNnqbJMyxEbnr0T2hIjMF5G52Cn7hBneEDIIKAd8HhoS9lLQAUWKiFwgIiuA5sDHIvJZ0DHlV6ij3p7yuouA0aq6INioIkdERgLfAHVFZIWIXBt0TBHWAugOtA193uaEWmCJoBqQEvqu/Ba7xpzjkKJE5pW/nHPOuRjiLWbnnHMuhnhids4552KIJ2bnnHMuhnhids4552KIJ2bnnHMuhnhids4552KIJ2bnnHMuhnhidq4QEZFJmYpTpInIJUHH5JzblxcYca4QEpGbgDbApaHJA5xzMSLqk1g452KLiFwBnANc5EnZudjjidm5QkREumBzg3dW1V1Bx+Oc258nZucKidCcsDcDnVQ1Leh4nHPZ82vMzhUSIrIOWA9sDT01UFVfDTAk51w2PDE755xzMcSHSznnnHMxxBOzc845F0M8MTvnnHMxxBOzc845F0M8MTvnnHMxxBOzc845F0M8MTvnnHMxxBOzc845F0P+H0wWqjbf6qUjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huberloss_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huberloss_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huberloss_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e80d8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f9ad53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huberloss_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b9ac4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.5900 - mae: 0.9428 - val_loss: 0.2318 - val_mae: 0.5300\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2150 - mae: 0.5134 - val_loss: 0.1962 - val_mae: 0.4847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204ec104d30>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f7746",
   "metadata": {},
   "source": [
    "## Saving & Loading Models with Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef252f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f06e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huberloss_fn\": huberloss_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8fbe09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.2041 - mae: 0.4971 - val_loss: 0.1941 - val_mae: 0.4760\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.1988 - mae: 0.4889 - val_loss: 0.2029 - val_mae: 0.4852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204f37345b0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1604fc",
   "metadata": {},
   "source": [
    "If we wanted our huber loss function to haver a threshold, we could do that as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05b09469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "386e3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e51d0835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 0.2190 - mae: 0.4870 - val_loss: 0.2506 - val_mae: 0.4899\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.2164 - mae: 0.4835 - val_loss: 0.2157 - val_mae: 0.4674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204f3a4eee0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81e4f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8983494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a403b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2131 - mae: 0.4787 - val_loss: 0.2228 - val_mae: 0.4708\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2094 - mae: 0.4745 - val_loss: 0.2351 - val_mae: 0.4814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204ec0fc610>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8188c18",
   "metadata": {},
   "source": [
    "Now we could create a class with the huber loss function with its own call method and configuration threshold all in one, and then assign a variable to that object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f751d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad19f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a2181c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f05b69a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.7537 - mae: 0.9386 - val_loss: 0.5733 - val_mae: 0.6871\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2631 - mae: 0.5303 - val_loss: 0.4541 - val_mae: 0.6010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204f6080e80>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1825834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ac19ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48a9d15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.2410 - mae: 0.5066 - val_loss: 0.3598 - val_mae: 0.5484\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2282 - mae: 0.4957 - val_loss: 0.2517 - val_mae: 0.4930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204f658c910>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9f9f740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c86f34",
   "metadata": {},
   "source": [
    "## Different Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fdb9f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc8a6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f81177b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d66d39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6df939a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.7384 - mae: 0.9251 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.6389 - mae: 0.5124 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204f78ac400>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "394f57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b61a9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64cd7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Class for L1 Regulization\n",
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a062ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7aec2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3e135cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 1.7839 - mae: 0.9155 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.6402 - mae: 0.5332 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204f4f61ee0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89556dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d74f913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0e624",
   "metadata": {},
   "source": [
    "## Custom Metrics inside of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3cb9d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "acf812a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de91932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.8413 - huber_fn: 0.7952\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.5001 - huber_fn: 0.2449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204f91f6bb0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d029e8",
   "metadata": {},
   "source": [
    "One issue that can arise from using the function for multiple fields such as loss and metrics is that there can be a floating point precision error where the values are not exact. One example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0f15d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7ab4e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 0.1104 - huber_fn: 0.2248\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.1070 - huber_fn: 0.2176\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b19be0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1103866770863533, 0.11299403922789891)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6ecfc",
   "metadata": {},
   "source": [
    "## Metrics in Keras and Creating a Custom Streamed Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb0201",
   "metadata": {},
   "source": [
    "Keras has its own precision function. Let's take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ddc0f48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7795fa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "013f788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "348bd4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8b804ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51236451",
   "metadata": {},
   "source": [
    "Now let's create our own metric with the Huber Loss function we used earlier and then have it where that loss function is updated if the function is called for several instances. So it is keeping a tally if you will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6d4bbc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ecb99811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "73888477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7a7ce789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e8e8856d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3d387b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8edb76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cdb05837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.8741 - huber_metric_1: 0.8741\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2674 - huber_metric_1: 0.2674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204fab09eb0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f9fe3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "095dc42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "09c84cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2427 - huber_metric_1: 0.2427\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2303 - huber_metric_1: 0.2303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204fbf748e0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9f47bb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b09b36",
   "metadata": {},
   "source": [
    "Knowing now that the model metrics can hold our threshold in the metrics array, we could have built out class for the HuberMetric like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "254c0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e665efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f22fbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "314bd31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4250 - HuberMetric: 0.8510\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.1183 - HuberMetric: 0.2369\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2f9196f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4250105619430542, 0.4250104478068792)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still a discrepency but with different functions and it is much smaller\n",
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "77a40efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d784f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\",\n",
    "                                custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c411efc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 0.2260 - HuberMetric: 0.2260\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.2220 - HuberMetric: 0.2220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204fd5a68e0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "969f6461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ffc34",
   "metadata": {},
   "source": [
    "## Custom Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "11067c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cd081086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787948, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e5beb400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 3.0698 - val_loss: 1.3855\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7505 - val_loss: 0.4814\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5433 - val_loss: 0.4066\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4274 - val_loss: 0.3779\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4502 - val_loss: 0.3918\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4122823476791382"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_val_scaled, y_val))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3bfc96",
   "metadata": {},
   "source": [
    "Performance was okay, let's now create a class that we will build to hold our units, our activation function, our bias and will be able to work out the weights for the neurons and our input and output shape for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "35f7159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e2cf5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "308a2336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.7071 - val_loss: 0.6440\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.5697 - val_loss: 0.5576\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.484973669052124"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16596282",
   "metadata": {},
   "source": [
    "Creating our custom model better than the default one from the Sequential API one we built. Let's save the model and build upon this idea where we can build a custom multi layer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "05243f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0f4a1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5269cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape) # Debugging of custom layer\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6693c2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc34a2",
   "metadata": {},
   "source": [
    "We're getting None values... This is because we don't know the batch size in the first dimension. Lets now pass data through to this custom layer. But first,w e will split the dataset inputs into 2 parts in the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4f4349cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]\n",
    "\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_val_scaled_A, X_val_scaled_B = split_data(X_val_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# Printing the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc76fb6",
   "metadata": {},
   "source": [
    "Now our Class Object will recognize our inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2c2faad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (11610, 4)  X2.shape:  (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e582c51",
   "metadata": {},
   "source": [
    "Time to build out the model with the API and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8794f9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "hidden_A = keras.layers.Dense(30, activation='selu')(hidden_A)\n",
    "hidden_B = keras.layers.Dense(30, activation='selu')(hidden_B)\n",
    "concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66cb350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6e7632c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "359/363 [============================>.] - ETA: 0s - loss: 1.9110X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "363/363 [==============================] - 5s 11ms/step - loss: 1.9051 - val_loss: 1.9715\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 1.0005 - val_loss: 0.9388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202340180d0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=2,\n",
    "          validation_data=((X_val_scaled_A, X_val_scaled_B), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd9095",
   "metadata": {},
   "source": [
    "Now let's build a custom layer and build it into a new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "57ac4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bddec86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "342d3763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 2.5799 - val_loss: 2.6121\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.0507 - val_loss: 0.9970\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.8036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8036043643951416"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))\n",
    "model.evaluate(X_test_scaled, y_test) # Should be 162 batches for shape of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0bcaa",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009fb93",
   "metadata": {},
   "source": [
    "Let us now build a custom model using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "17b15bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4c4691e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs): # layers and neurons for inputs\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e4c35a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs): # explicit parameter is output dimension\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7c3cd814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 8s 20ms/step - loss: 15.2298\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 7s 20ms/step - loss: 3.0809\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 7s 20ms/step - loss: 0.7646\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 7s 20ms/step - loss: 1.2876\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 7s 20ms/step - loss: 0.7809\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5818\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "de3917fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_23_layer_call_and_return_conditional_losses, dense_23_layer_call_fn, dense_24_layer_call_and_return_conditional_losses, dense_24_layer_call_fn, dense_25_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "289620f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b52f796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 8s 21ms/step - loss: 0.7067\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 8s 21ms/step - loss: 0.4976\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 7s 21ms/step - loss: 0.8601\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 8s 21ms/step - loss: 0.8105\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 7s 21ms/step - loss: 0.5850\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c56a18c",
   "metadata": {},
   "source": [
    "We could have also used the Sequential API instead where we create an object instance of our class and then pass it through the keras api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c5836b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cb831ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 7s 18ms/step - loss: 1.4069\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 6s 18ms/step - loss: 0.5799\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 6s 18ms/step - loss: 0.4181\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 6s 17ms/step - loss: 0.3531\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 6s 17ms/step - loss: 0.3545\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.7453\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95460e2",
   "metadata": {},
   "source": [
    "## Defining loss functions based on weights & activation functions in hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c928e8",
   "metadata": {},
   "source": [
    "In the following example, we will build a custom loss model with 5 hidden layers and an output layer. There will be an auxiliary output as well for the hidden layer. This output will be the reconstruction loss (mean square difference between reconstruction and inputs). This is to promoto the model to preserve as much information as possible in the hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "53ed4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        # super().build(batch_input_shape) super method doesn't work in TF 2.4 or greater\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1bf509d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 8s 19ms/step - loss: 0.7817 - reconstruction_error: 0.8224\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 7s 19ms/step - loss: 0.4488 - reconstruction_error: 0.4047\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89201090",
   "metadata": {},
   "source": [
    "## Automatic Differentiation Example In TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f215deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example f(w1,w2) function \n",
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "attachments": {
    "derivative-2.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c2efeadc",
   "metadata": {},
   "source": [
    "Now if we wanted to compute the first derivative of this function, how could we do it? Well, we could use the average rate of change function shown below:\n",
    "\n",
    "![derivative-2.PNG](attachment:derivative-2.PNG)\n",
    "\n",
    "in the next cell, we can use a variable called eps which is a value really close to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e366f8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a very small value to help us compute the first derivate of f(w1, w2) \n",
    "w1, w2 = 5, 3\n",
    "eps = 1e-6 # small value\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767618e",
   "metadata": {},
   "source": [
    "The first derivative of the function would yield f'(w1', w2) = 6 * w1 + 2 * w2 and f'(w1, w2') = 2*w1\n",
    "\n",
    "Now if we plug in w1 = 5 and w2 = 3 w.r.t w1, we would get 6(5) + 2(3) = 36\n",
    "\n",
    "Let's check w.r.t w2 now. This should yield roughly: 2*5 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6297b7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94364544",
   "metadata": {},
   "source": [
    "Great! Now this function is useful in this scenario... but unfortunately not for a neural network. It would be very complex and we would run into several problems calculating partial derivatives. Luckily we can use the tf.GradientTape method in Tensorflow to help with this in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "895dfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "331ff625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18965069",
   "metadata": {},
   "source": [
    "**NOTE:** This method can only be used to compute one set of gradients. The below cell shows what happens if we try with 2 seperate gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ca64b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210026e",
   "metadata": {},
   "source": [
    "To fix this, we just need to set *persistent = True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3b03c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "del tape # Delete tape to free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b2ba807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3ce3937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2]) # Doesn't work with anything other than variables already defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f69e0fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622a07f",
   "metadata": {},
   "source": [
    "The above will only work if we are \"Watching\" the tensors involving every operation related to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8ec33564",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6fcf3420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9c495",
   "metadata": {},
   "source": [
    "We can also do mathematical operations with our tape too within our functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4ca386c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.) # 40\n",
    "    z2 = f(w1, w2 + 5.) # 46\n",
    "    z3 = f(w1, w2 + 7.) # 50 (should sum to 136)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5e0c7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5fc69b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1e1526f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians # Right back to what we had prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e5b324d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians # After reduce sum and stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4e22d",
   "metadata": {},
   "source": [
    "We also may want to stop gradients from backpropagating through certain parts of the neural network. To do this, we can use tensorflows stop_gradient function to assist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "af58f8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2]) # Only input shape, None for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f4d885ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x) # Issue with softplus function resulting in NaN output\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992822f",
   "metadata": {},
   "source": [
    "We run into the issue above because autodiff ends up com‐\n",
    "puting infinity divided by infinity (which returns NaN). So we can just simply return the derivative of the softplus function shown below with a custom_gradient decorator from TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "da4b8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix\n",
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2aad3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "50eb31f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa777d1",
   "metadata": {},
   "source": [
    "## Custom Training Loops with AutoDifferentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "628cae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "880bfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32): # Randomly samples batch of instances from training set\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d6b8de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that displayed training status with number of stuss and the mean loss as well\n",
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "376391c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded0bb8",
   "metadata": {},
   "source": [
    "If we want to get fancier with a progress bar, typically how tensorflow's Sequential API Operates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5a04541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c09f39b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 3500/10000 [=>....]'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_bar(3500, 10000, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c0ef5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4acf7339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fe44d2",
   "metadata": {},
   "source": [
    "Let's now define hyperparameters, an optimizer, the loss function of our choosing and some metrics to go along with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7acad80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6fb34af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.4477 - mean_absolute_error: 0.5749\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.6291 - mean_absolute_error: 0.5146\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6780 - mean_absolute_error: 0.5322\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6865 - mean_absolute_error: 0.5320\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6436 - mean_absolute_error: 0.5190\n"
     ]
    }
   ],
   "source": [
    "# Now for some magic\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f15d2d",
   "metadata": {},
   "source": [
    "## Custom Tensorflow Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a63e4",
   "metadata": {},
   "source": [
    "Let us start this section with simple custom function that returns the cube of an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dee2f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d916802d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4232445d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens if we place tensorflow constants inside\n",
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83795b0",
   "metadata": {},
   "source": [
    "Neat, but Tensorflow can actually do this for us with the *tf.function* call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "efc49413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x205034a7730>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "57db66f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f70c0",
   "metadata": {},
   "source": [
    "Now we have a custom tensorflow function. Great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "75a1b24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e9b4a1",
   "metadata": {},
   "source": [
    "## More on TF Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e740d7",
   "metadata": {},
   "source": [
    "Every time a function is traced, a new concrete function is created. You can directly obtain a concrete function, by using get_concrete_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "df801e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x205034a7040>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e993edb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "bbe4dac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ca651",
   "metadata": {},
   "source": [
    "## TF Function Definitions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b29bba5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x205034a7040>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2d941562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "82b802d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "45ca2d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d0fa44f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "216bcc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "15a884ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_cube_613383\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33c7ef",
   "metadata": {},
   "source": [
    "## Using TF Functions as a decorator and extracting their computation graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a720de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bc936263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0ec54878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ac3978ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: 2\n",
      "print: 3\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x000002050355BCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x000002050355BCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x000002050355BCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x000002050355BCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # New shape: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "15640dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6a546672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1ac3de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.53214884 0.21943843]\n",
      "  [0.549847   0.85885656]]\n",
      "\n",
      " [[0.46057808 0.4719727 ]\n",
      "  [0.5660145  0.22303593]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe447d",
   "metadata": {},
   "source": [
    "## How to Use Autograph to Capture Control Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3ac4f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a1e17b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "11710176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "23580257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic loop with tf.while_loop()\n",
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "acf59cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ab2e4563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7606ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ab7631ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c0ad0f",
   "metadata": {},
   "source": [
    "## Handling Variable and Other Resources in TF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "81c7565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7de1b194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment(counter)\n",
    "increment(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ee214541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "07c4e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f1408803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4b4b6622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d22b72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "691e70ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "214abfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1fd5aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown('```python\\n{}\\n```'.format(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c7992c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add(x):\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal x\n",
       "            (x,) = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x = ag__.ld(x)\n",
       "            x += 1\n",
       "        i = ag__.Undefined('i')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476eb31e",
   "metadata": {},
   "source": [
    "## How to use TF Functions with tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8d2435e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c8ddb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "15f36907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "58157f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "51671489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9082ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "359/363 [============================>.] - ETA: 0s - loss: 1.2686 - my_mae: 0.7728Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - 5s 11ms/step - loss: 1.2583 - my_mae: 0.7690 - val_loss: 0.4567 - val_my_mae: 0.4741\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4395 - my_mae: 0.4758 - val_loss: 1.6967 - val_my_mae: 0.4775\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4191 - my_mae: 0.4635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4191416800022125, 0.4635005593299866]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e1096",
   "metadata": {},
   "source": [
    "You can turn this off by creating the model with dynamic=True (or calling super().__init__(dynamic=True, **kwargs) in the model's constructor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e73b6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "74d62920",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "439ff1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.570329666137695, 2.0695180892944336]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_val_scaled[:64], y_val[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cdb0524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without running dynamically\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "46d8f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True) # add run_eargerly method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3ba6f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.597047805786133, 2.0707335472106934]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_val_scaled[:64], y_val[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d9962",
   "metadata": {},
   "source": [
    "## Writing Custom Optimizer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b0a71404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay) # \n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0a2195cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 4.6434\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.5212\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8948\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7402\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20505eb6a30>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94335aa0",
   "metadata": {},
   "source": [
    "# End of Chapter Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d69f69",
   "metadata": {},
   "source": [
    "1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
    "2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences\n",
    "between the two?\n",
    "3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n",
    "4. Can you name six other data structures available in TensorFlow, beyond regular\n",
    "tensors?\n",
    "5. A custom loss function can be defined by writing a function or by subclassing the\n",
    "keras.losses.Loss class. When would you use each option?\n",
    "6. Similarly, a custom metric can be defined in a function or a subclass of\n",
    "keras.metrics.Metric. When would you use each option?\n",
    "7. When should you create a custom layer versus a custom model?\n",
    "8. What are some use cases that require writing your own custom training loop?\n",
    "9. Can custom Keras components contain arbitrary Python code, or must they be\n",
    "convertible to TF Functions?\n",
    "10. What are the main rules to respect if you want a function to be convertible to a\n",
    "TF Function?\n",
    "11. When would you need to create a dynamic Keras model? How do you do that?\n",
    "Why not make all your models dynamic?\n",
    "12. Implement a custom layer that performs Layer Normalization (we will use this\n",
    "type of layer in Chapter 15):\n",
    "\n",
    "    a. The build() method should define two trainable weights α and β, both of\n",
    "    shape input_shape[-1:] and data type tf.float32. α should be initialized\n",
    "    with 1s, and β with 0s.\n",
    "    \n",
    "    b. The call() method should compute the mean μ and standard deviation σ of\n",
    "    each instance’s features. For this, you can use tf.nn.moments(inputs,\n",
    "    axes=-1, keepdims=True), which returns the mean μ and the variance σ\n",
    "    2 of all instances (compute the square root of the variance to get the standard\n",
    "    deviation). Then the function should compute and return α⊗(X - μ)/(σ + ε) +\n",
    "    β, where ⊗ represents itemwise multiplication (*) and ε is a smoothing term\n",
    "    (small constant to avoid division by zero, e.g., 0.001).\n",
    "    \n",
    "    c. Ensure that your custom layer produces the same (or very nearly the same)\n",
    "    output as the keras.layers.LayerNormalization layer.\n",
    "    <br><br/>\n",
    "\n",
    "13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
    "(see Chapter 10).\n",
    "\n",
    "    a. Display the epoch, iteration, mean training loss, and mean accuracy over each\n",
    "    epoch (updated at each iteration), as well as the validation loss and accuracy at\n",
    "    the end of each epoch.\n",
    "    \n",
    "    b. Try using a different optimizer with a different learning rate for the upper lay‐\n",
    "    ers and the lower layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a43fac",
   "metadata": {},
   "source": [
    "***1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?***\n",
    "\n",
    "A: Tensorflow is a machine learning framework that can be used to design, build and train deep learning models. The name is derived from the operations that neural networks perform on multidimensional data arrays. They are actually called tensors so it is a flow of tensors across layers.  Some main features are that is it open source library filled with tons of useful functions, it is scalable, has pre build architectures for deep networks, has a stable API that let's users build their own networks, and class fucntions and a plethora of other unique features. Another popular deep learning library is PyTorch from Facebook. \n",
    "\n",
    "***2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences\n",
    "between the two?***\n",
    "\n",
    "A: Tensorflow is not a drop-in replacement. As a matter of fact there can be data discrepencies between 64bit and 32bit floating numbers where TensorFlow uses primarily 32-bit as default where NumPy is 64-bit. Although it is very similar to NumPy and it can actually perform same operations using tf.Tensors in Tensorflow with it, They are not exactly interchangable. Main differences are regarding the floating point numbers, functions are not exactly the same and NumPy arrays are mutable, TensorFlow tensors are not.\n",
    "\n",
    "***3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?***\n",
    "\n",
    "A: Yes, tested in the below cell.\n",
    "\n",
    "***4. Can you name six other data structures available in TensorFlow, beyond regular\n",
    "tensors?***\n",
    "\n",
    "A: Besides regular tensors there are other types of tensors and a select other. They are listed below with a brief description:\n",
    "\n",
    "1. Sparse Tensors - Represent tensors containing mostly zeros\n",
    "2. Tensor Arrays - Lists of tensors with same shape and data type\n",
    "3. Ragged Tensors - Static lists of lists of tensors with same shape and data type\n",
    "4. String Tensors - Byte strings of type tf.string\n",
    "5. Sets - Set of tensors. Ex. td.constant([[1,2], [3,4]]) is 2 sets: {1,2}, {3,4}\n",
    "6. Queues - Data structures that store tensors across multiple steps. Typically FIFO (First in first out)\n",
    "\n",
    "***5. A custom loss function can be defined by writing a function or by subclassing the\n",
    "keras.losses.Loss class. When would you use each option?***\n",
    "\n",
    "A: If you're looking for a quick implementation, thne simply writing a function will suffice. But if you want to keep the threshold for your model after you save it, it would be best to use the loss subclass.\n",
    "\n",
    "***6. Similarly, a custom metric can be defined in a function or a subclass of\n",
    "keras.metrics.Metric. When would you use each option?***\n",
    "\n",
    "A: For the same reason. If the function has hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class. Otherwise, a simple function on the spot will do. \n",
    "\n",
    "***7. When should you create a custom layer versus a custom model?***\n",
    "\n",
    "A: You should subclass layers and subclass models and then distinguish the layers seperately so the model with the objects you will train on are seperate and easily seperable. \n",
    "\n",
    "***8. What are some use cases that require writing your own custom training loop?***\n",
    "\n",
    "A: One example is what we discussed in Chapter 10 where you need different optimizers in a Wide & Deep Network where it splits. You could also write custom models to do exactly what you want after each iteration and they are generally more traceable as opposed to the ones TF provides you, like if you wanted to track something different metrics you customly create.\n",
    "\n",
    "***9. Can custom Keras components contain arbitrary Python code, or must they be\n",
    "convertible to TF Functions?***\n",
    "\n",
    "A: Python code can be wrapped in Keras components by using the td.function() command like the following: \n",
    "\n",
    "def cube(x):\n",
    "    return x ** 3\n",
    "    \n",
    "tf_cube = tf.function(cube) \n",
    "\n",
    "that would allow us to get the same output as our function but in tensors.\n",
    "\n",
    "You could also do the opposite where you wrap it like tf.py_function but it may not work as you need.\n",
    "\n",
    "***10. What are the main rules to respect if you want a function to be convertible to a\n",
    "TF Function?***\n",
    "\n",
    "A: Here is a general list of rules from the textbook:\n",
    "\n",
    "- If you call any external library, including NumPy or even the standard library,\n",
    "  this call will run only during tracing; it will not be part of the graph. So, make sure you use   tf.reduce_sum() instead of np.sum(), tf.sort() instead of the built-in sorted() function, and     so on (unless you really want the code to run only during tracing).\n",
    "  \n",
    "- You can call other Python functions or TF Functions, but they should follow the\n",
    "  same rules, as TensorFlow will capture their operations in the computation\n",
    "  graph. Note that these other functions do not need to be decorated with\n",
    "  @tf.function.\n",
    "  \n",
    "- If the function creates a TensorFlow variable (or any other stateful TensorFlow\n",
    "  object, such as a dataset or a queue), it must do so upon the very first call, and\n",
    "  only then, or else you will get an exception. It is usually preferable to createvariables         outside of the TF Function (e.g., in the build() method of a custom\n",
    "  layer). If you want to assign a new value to the variable, make sure you call its\n",
    "  assign() method, instead of using the = operator.\n",
    "  \n",
    "- The source code of your Python function should be available to TensorFlow. If\n",
    "  the source code is unavailable (for example, if you define your function in the\n",
    "  Python shell, which does not give access to the source code, or if you deploy only\n",
    "  the compiled *.pyc Python files to production), then the graph generation process\n",
    "  will fail or have limited functionality.\n",
    "  \n",
    "- TensorFlow will only capture for loops that iterate over a tensor or a dataset. So\n",
    "  make sure you use for i in tf.range(x) rather than for i in range(x), or\n",
    "  else the loop will not be captured in the graph. Instead, it will run during tracing.\n",
    "  (This may be what you want if the for loop is meant to build the graph, for\n",
    "  example to create each layer in a neural network.)\n",
    "  \n",
    "- As always, for performance reasons, you should prefer a vectorized implementa‐\n",
    "  tion whenever you can, rather than using loops.\n",
    "  \n",
    "***11. When would you need to create a dynamic Keras model? How do you do that?\n",
    "Why not make all your models dynamic?***\n",
    "\n",
    "A: As a first, it is super useful for debugging. You can also use any Python debugger to verify your code as well, custom components may not have the same success. Setting a model to be dynamic is as easy as setting *dynamic=True*. You wouldn't want all models to be dynamic as it prevents Keras from using TensorFlow's graph features which in turn limits your models' exportability and portability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ad9417fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "49aade6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4c02e1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12. Implement a custom layer that performs Layer Normalization (we will use this\\ntype of layer in Chapter 15):\\n\\n    a. The build() method should define two trainable weights α and β, both of\\n    shape input_shape[-1:] and data type tf.float32. α should be initialized\\n    with 1s, and β with 0s.\\n    \\n    b. The call() method should compute the mean μ and standard deviation σ of\\n    each instance’s features. For this, you can use tf.nn.moments(inputs,\\n    axes=-1, keepdims=True), which returns the mean μ and the variance σ\\n    2 of all instances (compute the square root of the variance to get the standard\\n    deviation). Then the function should compute and return α⊗(X - μ)/(σ + ε) +\\n    β, where ⊗ represents itemwise multiplication (*) and ε is a smoothing term\\n    (small constant to avoid division by zero, e.g., 0.001).\\n    \\n    c. Ensure that your custom layer produces the same (or very nearly the same)\\n    output as the keras.layers.LayerNormalization layer.\\n    <br><br/>'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 12\n",
    "'''12. Implement a custom layer that performs Layer Normalization (we will use this\n",
    "type of layer in Chapter 15):\n",
    "\n",
    "    a. The build() method should define two trainable weights α and β, both of\n",
    "    shape input_shape[-1:] and data type tf.float32. α should be initialized\n",
    "    with 1s, and β with 0s.\n",
    "    \n",
    "    b. The call() method should compute the mean μ and standard deviation σ of\n",
    "    each instance’s features. For this, you can use tf.nn.moments(inputs,\n",
    "    axes=-1, keepdims=True), which returns the mean μ and the variance σ\n",
    "    2 of all instances (compute the square root of the variance to get the standard\n",
    "    deviation). Then the function should compute and return α⊗(X - μ)/(σ + ε) +\n",
    "    β, where ⊗ represents itemwise multiplication (*) and ε is a smoothing term\n",
    "    (small constant to avoid division by zero, e.g., 0.001).\n",
    "    \n",
    "    c. Ensure that your custom layer produces the same (or very nearly the same)\n",
    "    output as the keras.layers.LayerNormalization layer.\n",
    "    <br><br/>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fad79e",
   "metadata": {},
   "source": [
    "### A. The build() method should define two trainable weights α and β, both of shape input_shape[-1:] and data type tf.float32. α should be initialized with 1s, and β with 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "40a3303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init_(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(name=\"Alpha\", shape=batch_input_shape[-1:], initializer=\"ones\")\n",
    "        self.beta = self.add_weight(name=\"Beta\", shape=batch_input_shape[-1:], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e3058",
   "metadata": {},
   "source": [
    "### B. The call() method should compute the mean μ and standard deviation σ of each instance’s features. For this, you can use tf.nn.moments(inputs, axes=-1, keepdims=True), which returns the mean μ and the variance σ 2 of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return α⊗(X - μ)/(σ + ε) + β, where ⊗ represents itemwise multiplication (*) and ε is a smoothing term (small constant to avoid division by zero, e.g., 0.001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4c781c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, const=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.const = const\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(name=\"alpha\", shape=batch_input_shape[-1:], initializer=\"ones\")\n",
    "        self.beta = self.add_weight(name=\"beta\", shape=batch_input_shape[-1:], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(variance + self.const)) + self.beta\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"const\": self.const}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8c6d8",
   "metadata": {},
   "source": [
    "### C. Ensure that your custom layer produces the same (or very nearly the same) output as the keras.layers.LayerNormalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4001d4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.894674e-08>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3605f22",
   "metadata": {},
   "source": [
    "That's as close as were gonna get. That is a very small number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e7529832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\\n(see Chapter 10).\\n\\n    a. Display the epoch, iteration, mean training loss, and mean accuracy over each\\n    epoch (updated at each iteration), as well as the validation loss and accuracy at\\n    the end of each epoch.\\n    \\n    b. Try using a different optimizer with a different learning rate for the upper layers \\n    and the lower layers.'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 13\n",
    "'''13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
    "(see Chapter 10).\n",
    "\n",
    "    a. Display the epoch, iteration, mean training loss, and mean accuracy over each\n",
    "    epoch (updated at each iteration), as well as the validation loss and accuracy at\n",
    "    the end of each epoch.\n",
    "    \n",
    "    b. Try using a different optimizer with a different learning rate for the upper layers \n",
    "    and the lower layers.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb74eed",
   "metadata": {},
   "source": [
    "### A. Display the epoch, iteration, mean training loss, and mean accuracy over each    epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "34e8d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_val, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_val, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b36429e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model from End of Chapter 10 Exercises\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(400, activation=\"relu\"),\n",
    "    keras.layers.Dense(150, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9165bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom variables we will need\n",
    "epoch_num = 10 # Defined Epoch Number\n",
    "batch_size = 32 # Defined Batch Size\n",
    "steps = len(X_train) // batch_size # Steps we need for proper batch sizes \n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy # loss function\n",
    "mean_for_loss = keras.metrics.Mean() # Mean training loss\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01) #Adam optimizer\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d244c1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - mean: 0.5515 - sparse_categorical_accuracy: 0.8024\n",
      "Validation Loss:  0.45274618\n",
      "Validation Accuracy:  0.842\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - mean: 0.4140 - sparse_categorical_accuracy: 0.8517\n",
      "Validation Loss:  0.43626845\n",
      "Validation Accuracy:  0.8512\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - mean: 0.3984 - sparse_categorical_accuracy: 0.8593\n",
      "Validation Loss:  0.4754962\n",
      "Validation Accuracy:  0.8476\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - mean: 0.3811 - sparse_categorical_accuracy: 0.8653\n",
      "Validation Loss:  0.45564777\n",
      "Validation Accuracy:  0.8514\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - mean: 0.3713 - sparse_categorical_accuracy: 0.8690\n",
      "Validation Loss:  0.44140968\n",
      "Validation Accuracy:  0.8666\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - mean: 0.3639 - sparse_categorical_accuracy: 0.8732\n",
      "Validation Loss:  0.40878305\n",
      "Validation Accuracy:  0.8668\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - mean: 0.3539 - sparse_categorical_accuracy: 0.8764\n",
      "Validation Loss:  0.44296777\n",
      "Validation Accuracy:  0.8608\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - mean: 0.3682 - sparse_categorical_accuracy: 0.8728\n",
      "Validation Loss:  0.39843515\n",
      "Validation Accuracy:  0.8694\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - mean: 0.3558 - sparse_categorical_accuracy: 0.8762\n",
      "Validation Loss:  0.43707904\n",
      "Validation Accuracy:  0.8642\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - mean: 0.3446 - sparse_categorical_accuracy: 0.8797\n",
      "Validation Loss:  0.3914873\n",
      "Validation Accuracy:  0.8732\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "for epoch in range(1, epoch_num + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, epoch_num))\n",
    "    for step in range(1, steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        status = OrderedDict()\n",
    "        mean_for_loss(loss)\n",
    "        status[\"loss\"] = mean_for_loss.result().numpy()\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "            status[metric.name] = metric.result().numpy()\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_for_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_for_loss, metrics)\n",
    "    y_pred = model(X_val)\n",
    "    status[\"val_loss\"] = np.mean(loss_fn(y_val, y_pred))\n",
    "    status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "        tf.constant(y_val, dtype=np.float32), y_pred))\n",
    "    for metric in [mean_for_loss] + metrics:\n",
    "        metric.reset_states()\n",
    "    print(\"Validation Loss: \", status[\"val_loss\"])\n",
    "    print(\"Validation Accuracy: \", status[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a40d0c",
   "metadata": {},
   "source": [
    "### B. Try using a different optimizer with a different learning rate for the upper layers and the lower layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "31270d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(400, activation=\"relu\"), # Change in Dense Layer \n",
    "    keras.layers.Dense(150, activation=\"relu\"),  # Change in Dense Layer\n",
    "])\n",
    "upper_layers = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model = keras.models.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3256e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(learning_rate=10e-6, momentum=0.95)  # Could Possibly Cradle\n",
    "upper_optimizer = keras.optimizers.Nadam(learning_rate=10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d46f3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom variables we will need\n",
    "epoch_num = 10 # Defined Epoch Number\n",
    "batch_size = 32 # Batch Size\n",
    "steps = len(X_train) // batch_size # Steps we need for proper batch sizes \n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy # loss function\n",
    "mean_for_loss = keras.metrics.Mean() # Mean training loss\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ac33e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - mean: 1.1122 - sparse_categorical_accuracy: 0.755471\n",
      "Validation Loss:  0.5797922\n",
      "Validation Accuracy:  0.7928\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - mean: 0.5686 - sparse_categorical_accuracy: 0.7967\n",
      "Validation Loss:  0.54308844\n",
      "Validation Accuracy:  0.8084\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - mean: 0.5404 - sparse_categorical_accuracy: 0.8081\n",
      "Validation Loss:  0.50494415\n",
      "Validation Accuracy:  0.8188\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - mean: 0.5179 - sparse_categorical_accuracy: 0.8152\n",
      "Validation Loss:  0.5515726\n",
      "Validation Accuracy:  0.8108\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - mean: 0.5003 - sparse_categorical_accuracy: 0.8209\n",
      "Validation Loss:  0.5496986\n",
      "Validation Accuracy:  0.808\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - mean: 0.4880 - sparse_categorical_accuracy: 0.8264\n",
      "Validation Loss:  0.50407946\n",
      "Validation Accuracy:  0.8232\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - mean: 0.4852 - sparse_categorical_accuracy: 0.8282\n",
      "Validation Loss:  0.48367983\n",
      "Validation Accuracy:  0.8364\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - mean: 0.4723 - sparse_categorical_accuracy: 0.8336\n",
      "Validation Loss:  0.53904736\n",
      "Validation Accuracy:  0.8062\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - mean: 0.4813 - sparse_categorical_accuracy: 0.8317\n",
      "Validation Loss:  0.47981662\n",
      "Validation Accuracy:  0.844\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - mean: 0.4659 - sparse_categorical_accuracy: 0.8361\n",
      "Validation Loss:  0.45011017\n",
      "Validation Accuracy:  0.8464\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epoch_num + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, epoch_num))\n",
    "    for step in range(1, steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        status = OrderedDict()\n",
    "        mean_for_loss(loss)\n",
    "        status[\"loss\"] = mean_for_loss.result().numpy()\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "            status[metric.name] = metric.result().numpy()\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_for_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_for_loss, metrics)\n",
    "    y_pred = model(X_val)\n",
    "    status[\"val_loss\"] = np.mean(loss_fn(y_val, y_pred))\n",
    "    status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "        tf.constant(y_val, dtype=np.float32), y_pred))\n",
    "    for metric in [mean_for_loss] + metrics:\n",
    "        metric.reset_states()\n",
    "    print(\"Validation Loss: \", status[\"val_loss\"])\n",
    "    print(\"Validation Accuracy: \", status[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf8be3",
   "metadata": {},
   "source": [
    "Hmm, didn't look like that helped.. Let's try and build a different model now and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8a02713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(400, activation=\"relu\"), # Change in Dense Layer \n",
    "    keras.layers.Dense(200, activation=\"relu\"),  # Change in Dense Layer\n",
    "    keras.layers.Dense(100, activation=\"relu\") # Change in Dense Layer\n",
    "])\n",
    "upper_layers = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model = keras.models.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cf5876d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(learning_rate=10e-6, momentum=0.99)  # Could Possibly Cradle\n",
    "upper_optimizer = keras.optimizers.Nadam(learning_rate=10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "abcb24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom variables we will need\n",
    "epoch_num = 10 # Defined Epoch Number\n",
    "batch_size = 64 # Change Batch Size\n",
    "steps = len(X_train) // batch_size # Steps we need for proper batch sizes \n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy # loss function\n",
    "mean_for_loss = keras.metrics.Mean() # Mean training loss\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "08c27310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - mean: 1.3283 - sparse_categorical_accuracy: 0.684221\n",
      "Validation Loss:  0.64274704\n",
      "Validation Accuracy:  0.7594\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - mean: 0.6099 - sparse_categorical_accuracy: 0.7638\n",
      "Validation Loss:  0.5742773\n",
      "Validation Accuracy:  0.7774\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - mean: 0.5693 - sparse_categorical_accuracy: 0.7862\n",
      "Validation Loss:  0.5929462\n",
      "Validation Accuracy:  0.7934\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - mean: 0.5450 - sparse_categorical_accuracy: 0.7889\n",
      "Validation Loss:  0.57417077\n",
      "Validation Accuracy:  0.784\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - mean: 0.5280 - sparse_categorical_accuracy: 0.8015\n",
      "Validation Loss:  0.5248538\n",
      "Validation Accuracy:  0.8118\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - mean: 0.5207 - sparse_categorical_accuracy: 0.8045\n",
      "Validation Loss:  0.57509094\n",
      "Validation Accuracy:  0.8048\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - mean: 0.5096 - sparse_categorical_accuracy: 0.8106\n",
      "Validation Loss:  0.5314624\n",
      "Validation Accuracy:  0.8094\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - mean: 0.4975 - sparse_categorical_accuracy: 0.8196\n",
      "Validation Loss:  0.5176066\n",
      "Validation Accuracy:  0.821\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - mean: 0.4939 - sparse_categorical_accuracy: 0.8208\n",
      "Validation Loss:  0.5110815\n",
      "Validation Accuracy:  0.8218\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - mean: 0.4995 - sparse_categorical_accuracy: 0.8166\n",
      "Validation Loss:  0.5443365\n",
      "Validation Accuracy:  0.7996\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epoch_num + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, epoch_num))\n",
    "    for step in range(1, steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        status = OrderedDict()\n",
    "        mean_for_loss(loss)\n",
    "        status[\"loss\"] = mean_for_loss.result().numpy()\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "            status[metric.name] = metric.result().numpy()\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_for_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_for_loss, metrics)\n",
    "    y_pred = model(X_val)\n",
    "    status[\"val_loss\"] = np.mean(loss_fn(y_val, y_pred))\n",
    "    status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "        tf.constant(y_val, dtype=np.float32), y_pred))\n",
    "    for metric in [mean_for_loss] + metrics:\n",
    "        metric.reset_states()\n",
    "    print(\"Validation Loss: \", status[\"val_loss\"])\n",
    "    print(\"Validation Accuracy: \", status[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50c66a",
   "metadata": {},
   "source": [
    "Didn't really improve or do much better here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55906c08",
   "metadata": {},
   "source": [
    "# End of Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b2d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
