Chapter 17 introduces the reader to generative learning with autoencoders and GANS. This chapter started with reintroducing PCA with a linear autoencoder and then moved onto an example of stacked autoencoders to use on the MNIST Fashion dataset to try and reconstruct the images using the autoencoders. There were examples with methods such as tying the weights of the autoencoder and training one autoencoder in the stack at a time. We then move on to a CNN approach to autoencoders known as Convolutional Encoders and how they can be built for reassembling images or creating completely original images. We do the same thing with RNNs and go over different methods to reduce error and make the task of using autoencoders a bit smoother. The chapter ends talking about GANs (Generative Adversarial Networks) and how they work. the algorithm behind them and different types of GAN models such as StyleGANs and Deep Convolutional GANs.
The jupyter notebook for this chapter goes into greater depth for the topics discussed in this chapter. 
