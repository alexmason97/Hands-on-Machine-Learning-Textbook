Chapter 16 talks about what natural language processing is and how it can be achieved using RNNs and attention layers. The chapter talks about the ability to create a dataset, how to split it sequentially, and then building a RNN model to generate text output. The second half of the chapter goes over sentiment analysis with RNNs and how to build an Encoder-Decoder network for things like language translation between English and French. The other big NLP architecture is the transformer architecture which achieved impressive results without recurrent or convolutional layers. The chapter ends with different innovational papers in the field of natural language processing. 
